{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-s61hgmMRB3e"
   },
   "source": [
    "## Q1. Recognize the differences between supervised, semi-supervised, and unsupervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qn9slBhrQ-tl"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Supervised Learning: Supervised learning is the types of machine learning in which machines are trained using well \n",
    "\"labelled\" training data, and on basis of that data, machines predict the output.\n",
    "\n",
    "Semi-Supervised Learning: Semi-supervised learning is a type of machine learning. It refers to a learning problem that involves a small portion of labeled examples \n",
    "and a large number of unlabeled examples from which a model must learn and make predictions on new examples.\n",
    "\n",
    "Unsupervised Learning: Unsupervised learning is a type of algorithm that learns patterns from untagged data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gpd6NuESVAUc"
   },
   "source": [
    "## Q2. Describe in detail any five examples of classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tqj0TWjBVBhN"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1. Customer behavior prediction: Customers can be classified in different categories based on their buying patterns, web store browsing patterns etc.\n",
    "2. Malware classification: Multinomial classification – Classify the new / emerging malwares on the basis of comparable features of similar malwares\n",
    "3. Mushrooms Classification: Classify if a mushroom is edible or poisonous from it's physical features\n",
    "4. Document classification: Multinomial classification – Classifies documents in different categories\n",
    "5. Customer churn prediction: Binary classification – Whether a customer will churn or not in near future\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXjVKOdIW3H8"
   },
   "source": [
    "## Q3. Describe each phase of the classification process in detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQ0PtoNmW4TW"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Data aquiring: In this process data is collected\n",
    "data preprocessing: Different kind of preprocessing techniques are applied to turn the raw data into good data\n",
    "feature extraction: New features are extracted that might be usefull\n",
    "dimension reduction: If the dimension is too high dimentionality reduction techniques are applied\n",
    "passing data into classifier: Data is passed to the classification algorithm and it gets classified\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EVD3xXEYT3V"
   },
   "source": [
    "## Q4. Go through the SVM model in depth using various scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYGmpPuuYVC1"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "“Support Vector Machine” (SVM) is a supervised machine learning algorithm that can be used for both classification or regression challenges. \n",
    "However,  it is mostly used in classification problems. In the SVM algorithm, we plot each data item as a point in n-dimensional space \n",
    "with the value of each feature being the value of a particular coordinate. Then, we perform classification by finding the hyper-plane that differentiates \n",
    "the two classes very well.\n",
    "\n",
    "\n",
    "Senario 1: we have three hyper-planes (A, B, and C). Now, identify the right hyper-plane to classify stars and circles.\n",
    "Ans: You need to remember a thumb rule to identify the right hyper-plane: \"Select the hyper-plane which segregates the two classes better\". \n",
    "In this scenario, hyper-plane with largest margin has excellently performed this job.\n",
    "\n",
    "Senario 2: Here, we have three hyper-planes (A, B, and C) and all are segregating the classes well. Now, How can we identify the right hyper-plane?\n",
    "Ans; Again in this case the hyper-plane with largest margin between two classes is the right hyperplane\n",
    "\n",
    "Senario 3: In the scenario below, we can’t have linear hyper-plane between the two classes, so how does SVM classify these two classes?\n",
    "Ans: Use kernal tricks and transform the data to higher dimension then seperate it wil a hyper plane\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIvmuBXfboC2"
   },
   "source": [
    "## Q5. What are some of the benefits and drawbacks of SVM?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yi_XPEG2bpEF"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "benefits:\n",
    "    It works really well with a clear margin of separation\n",
    "    It is effective in high dimensional spaces.\n",
    "    It is effective in cases where the number of dimensions is greater than the number of samples.\n",
    "    It uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "\n",
    "drawbacks:\n",
    "    It doesn’t perform well when we have large data set because the required training time is higher\n",
    "    It also doesn’t perform very well, when the data set has more noise i.e. target classes are overlapping\n",
    "    SVM doesn’t directly provide probability estimates, these are calculated using an expensive five-fold cross-validation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgE3RCEjcOb1"
   },
   "source": [
    "## Q6. Go over the kNN model in depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4RoPHL5IcPnd"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Knn: KNN can be used for both classification and regression predictive problems. However, it is more widely used in classification problems in the industry\n",
    "  It is a lazy learner as it doesn't learn any relation in the training period instead it stores the data points and if a new data point comes it calculates the distance\n",
    "  between the point and n nearest neighbour and checks closest majority class. Then it assigns the new datapoint to the majority class.\n",
    "\n",
    "how to choose the value of k?\n",
    "we can plot a k vs validation error plot and choose the one with lower error and take the k value\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqjyvKjH8L5X"
   },
   "source": [
    "## Q8.For kNN, talk about how to measure the difference between the test and training results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xASr92RK8PnD"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Confusion Matrix, AUC score, presicion, recall, f1 score\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzpa15Qi8Y3Q"
   },
   "source": [
    "## Q9. Create the kNN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWUrBnil8Z7F"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "1. Load the data\n",
    "2. Initialise the value of k\n",
    "3. For getting the predicted class, iterate from 1 to total number of training data points\n",
    "     3.1 Calculate the distance between test data and each row of training data. Here we will use Euclidean distance as our distance metric since \n",
    "     it’s the most popular method. The other metrics that can be used are Chebyshev, cosine, etc.\n",
    "     3.2 Sort the calculated distances in ascending order based on distance values\n",
    "     3.3 Get top k rows from the sorted array\n",
    "     3.4 Get the most frequent class of these rows\n",
    "     3.5 Return the predicted class\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBRG3ScP-Yra"
   },
   "source": [
    "## Q10.What is a decision tree, exactly? What are the various kinds of nodes? Explain all in depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0gXei-y-aVK"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Descision tree is like a flow chart that shows clear pathway to a descision.\n",
    "Root node: This is the node that is the entry point of the tree\n",
    "Data node: These are the nodes that contains different condition for the tree on which way to go.\n",
    "Leaf node: This is the node that contains the output/ descisions\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8w0YuK3B99P"
   },
   "source": [
    "## Q11. Describe the different ways to scan a decision tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBEpACZFB_Cx"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Entropy,\n",
    "Gini\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xc0gdL-KGX8t"
   },
   "source": [
    "## Q12. Describe in depth the decision tree algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XMPs_XQGZHr"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Tree depth is a measure of how many splits a tree can make before coming to a prediction. \n",
    "This process could be continued further with more splitting until the tree is as pure as possible. \n",
    "The problem with many repetitions of this process is that this can lead to a very deep classification tree with many nodes.\n",
    "And lead to overfittng\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QieuJsThGrRK"
   },
   "source": [
    "## Q13. In a decision tree, what is inductive bias? What would you do to stop overfitting?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCOOKeebGsQe"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "descision tree is robust to noisy data and capable of learning disjunctive expressions. \n",
    "Decision tree learning method searches a completely expressive hypothesis . \n",
    "Avoids the difficulties of restricted hypothesis spaces. \n",
    "Its inductive bias is a preference for small trees over large trees.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTT-fYMlIwXu"
   },
   "source": [
    "## Q14.Explain advantages and disadvantages of using a decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uA7NZ_ELIxq7"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Advantage:\n",
    "          1. The algorithm is simple to understand, interpret and visualize as the idea is mostly used in our daily lives. \n",
    "          Output of a Decision Tree can be easily interpreted by humans.\n",
    "          2. Decision Tree looks like simple if-else statements which are very easy to understand.\n",
    "          3.  Decision Tree can be used for both classification and regression problems.\n",
    "          4. Decision Tree can handle both continuous and categorical variables.\n",
    "          5. No feature scaling required: No feature scaling required in case of Decision Tree \n",
    "          as it uses rule based approach instead of distance calculation.\n",
    "\n",
    "Disadvantage:\n",
    "          1. It generally leads to overfitting of the data which ultimately leads to wrong predictions.\n",
    "          2.  Decision Tree generally leads to the overfitting of data. Due to the overfitting, there are very high chances of high variance \n",
    "          in the output which leads to many errors in the final estimation and shows high inaccuracy in the results. \n",
    "          In order to achieve zero bias, it leads to high variance. \n",
    "          3. Little bit of noise can make it unstable which leads to wrong predictions.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnXk2eV9Syj7"
   },
   "source": [
    "## Q15. Describe in depth the problems that are suitable for decision tree learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwVa8Qs7S4Zi"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1. Overfitting: This is the main problem of the Decision Tree. It generally leads to overfitting of the data which ultimately leads to wrong predictions. \n",
    "In order to fit the data (even noisy data), it keeps generating new nodes and ultimately the tree becomes too complex to interpret. In this way, \n",
    "it loses its generalization capabilities. It performs very well on the trained data but starts making a lot of mistakes on the unseen data.\n",
    "\n",
    "2. High variance: As mentioned in point 1, Decision Tree generally leads to the overfitting of data. Due to the overfitting, there are very high chances of \n",
    "high variance in the output which leads to many errors in the final estimation and shows high inaccuracy in the results. In order to achieve zero bias, \n",
    "it leads to high variance. \n",
    "\n",
    "3. Unstable: Adding a new data point can lead to re-generation of the overall tree and all nodes need to be recalculated and recreated. \n",
    "\n",
    "4. Affected by noise: Little bit of noise can make it unstable which leads to wrong predictions.\n",
    "\n",
    "5. Not suitable for large datasets: If data size is large, then one single tree may grow complex and lead to overfitting. So in this case, \n",
    "we should use Random Forest instead of a single Decision Tree.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3UAf9r9c-4G"
   },
   "source": [
    "## Q16. Describe in depth the random forest model. What distinguishes a random forest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DEmahp4dAjq"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Random forest is an ensemble technique. It improves upon the bagging techniques and introduces more randomness to the trees so that trees become less correlated.\n",
    "Thus proving good results.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyN4aw9gyCob"
   },
   "source": [
    "## Q17. In a random forest, talk about OOB error and variable value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KX-CmmWyDrq"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "OOB error: It is a measure of the ammount of data that wasn't selected in any of the bootstarping. This data gets used for validation and helps to prevent data leakage.\n",
    "\n",
    "Variable value: It is a measure of the contribution of each variable in forming random forest.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ML Assignment 15.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
